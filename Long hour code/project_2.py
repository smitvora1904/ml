# -*- coding: utf-8 -*-
"""Project 2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10CwadNEQ-odsD86g64QZ-BNzNZ6kpvVs
"""

import numpy as np  
import matplotlib.pyplot as plt 
import pandas as pd

from google.colab import drive #to import google drive data

drive.mount('/content/drive') # to mount the drive data into colab cloud and enter the activation code

cd /content/drive/"My Drive/ML nishit sir/LHC"

dataset = pd.read_csv("parkinsons.csv")
dataset

dataset.describe()

dataset.shape



"""### **2.Perform the classification technique to determine the status of healthy and diseaseâ€™s class**"""

data_target = dataset['status'].values

data_features = dataset.drop(['name','status'], axis = 1)

disease = dataset.loc[data_target==1]

healthy = dataset.loc[data_target==0]

#Plot to show the difference in the classes given in the dataset.
plt.scatter(disease.iloc[:, 1], disease.iloc[:, 2], s=10, label='isDisease')
plt.scatter(healthy.iloc[:, 2], healthy.iloc[:, 2], s=10, label='Not Disease')
plt.title('Heart risk vs no risk')
plt.legend()
plt.show()

from sklearn.model_selection import train_test_split

X_input_features = np.array(data_features)
Y_target_variable = np.array(data_target)

X_train,X_test,Y_train,Y_test = train_test_split(X_input_features,Y_target_variable,test_size=0.20,random_state=32)

from sklearn.linear_model import LogisticRegression
model_logistic_regression = LogisticRegression()

model_logistic_regression.fit(X_train,Y_train)

Prediction_of_model = model_logistic_regression.predict(X_test)

from sklearn import metrics

confusion_matrixx = metrics.confusion_matrix(Y_test,Prediction_of_model)

confusion_matrixx

print("Accuracy:",metrics.accuracy_score(Y_test, Prediction_of_model))



"""### **Perform the dimensionality reduction technique and observe the accuracy graph w.r.t the number of dimensions.**"""

from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler.fit(data_features)
scaled_data = scaler.transform(data_features)
test_acc = []

x = [i for i in range(2,22)]

for i in range(2,22):
    pca = PCA(n_components=i)
    pca.fit(scaled_data)
    x_pca = pca.transform(scaled_data)

    # spliting data in train and test dataset 
    from sklearn.model_selection import train_test_split
    X_train, X_test, y_train, y_test = train_test_split(x_pca , data_target, test_size = 0.2, random_state=50)

    # training dataset
    from sklearn.linear_model import LogisticRegression
    Log_Reg =LogisticRegression(max_iter=5000).fit(X_train,y_train)

    #print("Training  score: ",Log_Reg.score(X_train, y_train))
    #print("Test  score: ",Log_Reg.score(X_test, y_test))

    from sklearn.metrics import classification_report,confusion_matrix
    prediction=Log_Reg.predict(X_test)
    #print(classification_report(y_test,prediction))


    # Create an array (so it is easier to calculate the accuracy)
    
    cm_df=confusion_matrix(y_test,prediction)
    cm = np.array(cm_df)
    Predict_accu = (cm[0,0]+cm[1,1])/cm.sum()
    
    print(Predict_accu)
    test_acc.append(Predict_accu)

plt.plot(x,test_acc,"-b")
plt.xlabel("PCA Values")
plt.ylabel("Accuracy")
plt.title("Accuracy with Incrwasing PCA Values")
plt.show()

